/**
 * Autogenerated by Avro
 * 
 * DO NOT EDIT DIRECTLY
 */
package com.databricks.spark.avro;  
@SuppressWarnings("all")
@org.apache.avro.specific.AvroGenerated
public class TestRecord extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"TestRecord\",\"namespace\":\"com.databricks.spark.avro\",\"fields\":[{\"name\":\"boolean\",\"type\":\"boolean\",\"default\":true},{\"name\":\"int\",\"type\":\"int\",\"default\":0},{\"name\":\"long\",\"type\":\"long\",\"default\":0},{\"name\":\"float\",\"type\":\"float\",\"default\":0.0},{\"name\":\"double\",\"type\":\"double\",\"default\":0.0},{\"name\":\"string\",\"type\":\"string\",\"default\":\"value\"},{\"name\":\"bytes\",\"type\":\"bytes\",\"default\":\"Ã¿\"},{\"name\":\"nested\",\"type\":{\"type\":\"record\",\"name\":\"SimpleRecord\",\"fields\":[{\"name\":\"nested1\",\"type\":\"int\",\"default\":0},{\"name\":\"nested2\",\"type\":\"string\",\"default\":\"string\"}]},\"default\":{\"nested1\":0,\"nested2\":\"string\"}},{\"name\":\"enum\",\"type\":{\"type\":\"enum\",\"name\":\"SimpleEnums\",\"symbols\":[\"SPADES\",\"HEARTS\",\"DIAMONDS\",\"CLUBS\"]},\"default\":\"SPADES\"},{\"name\":\"fixed\",\"type\":{\"type\":\"fixed\",\"name\":\"SimpleFixed\",\"size\":16},\"default\":\"string_length_16\"},{\"name\":\"intArray\",\"type\":{\"type\":\"array\",\"items\":\"int\"},\"default\":[1,2,3]},{\"name\":\"stringArray\",\"type\":{\"type\":\"array\",\"items\":\"string\"},\"default\":[\"a\",\"b\",\"c\"]},{\"name\":\"recordArray\",\"type\":{\"type\":\"array\",\"items\":\"SimpleRecord\"},\"default\":[{\"nested1\":0,\"nested2\":\"value\"},{\"nested1\":0,\"nested2\":\"value\"}]},{\"name\":\"enumArray\",\"type\":{\"type\":\"array\",\"items\":\"SimpleEnums\"},\"default\":[\"SPADES\",\"HEARTS\",\"SPADES\"]},{\"name\":\"fixedArray\",\"type\":{\"type\":\"array\",\"items\":\"SimpleFixed\"},\"default\":[\"foo\",\"bar\",\"baz\"]}]}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
  @Deprecated public boolean boolean$;
  @Deprecated public int int$;
  @Deprecated public long long$;
  @Deprecated public float float$;
  @Deprecated public double double$;
  @Deprecated public java.lang.CharSequence string;
  @Deprecated public java.nio.ByteBuffer bytes;
  @Deprecated public com.databricks.spark.avro.SimpleRecord nested;
  @Deprecated public com.databricks.spark.avro.SimpleEnums enum$;
  @Deprecated public com.databricks.spark.avro.SimpleFixed fixed;
  @Deprecated public java.util.List<java.lang.Integer> intArray;
  @Deprecated public java.util.List<java.lang.CharSequence> stringArray;
  @Deprecated public java.util.List<com.databricks.spark.avro.SimpleRecord> recordArray;
  @Deprecated public java.util.List<com.databricks.spark.avro.SimpleEnums> enumArray;
  @Deprecated public java.util.List<com.databricks.spark.avro.SimpleFixed> fixedArray;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>. 
   */
  public TestRecord() {}

  /**
   * All-args constructor.
   */
  public TestRecord(java.lang.Boolean boolean$, java.lang.Integer int$, java.lang.Long long$, java.lang.Float float$, java.lang.Double double$, java.lang.CharSequence string, java.nio.ByteBuffer bytes, com.databricks.spark.avro.SimpleRecord nested, com.databricks.spark.avro.SimpleEnums enum$, com.databricks.spark.avro.SimpleFixed fixed, java.util.List<java.lang.Integer> intArray, java.util.List<java.lang.CharSequence> stringArray, java.util.List<com.databricks.spark.avro.SimpleRecord> recordArray, java.util.List<com.databricks.spark.avro.SimpleEnums> enumArray, java.util.List<com.databricks.spark.avro.SimpleFixed> fixedArray) {
    this.boolean$ = boolean$;
    this.int$ = int$;
    this.long$ = long$;
    this.float$ = float$;
    this.double$ = double$;
    this.string = string;
    this.bytes = bytes;
    this.nested = nested;
    this.enum$ = enum$;
    this.fixed = fixed;
    this.intArray = intArray;
    this.stringArray = stringArray;
    this.recordArray = recordArray;
    this.enumArray = enumArray;
    this.fixedArray = fixedArray;
  }

  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call. 
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return boolean$;
    case 1: return int$;
    case 2: return long$;
    case 3: return float$;
    case 4: return double$;
    case 5: return string;
    case 6: return bytes;
    case 7: return nested;
    case 8: return enum$;
    case 9: return fixed;
    case 10: return intArray;
    case 11: return stringArray;
    case 12: return recordArray;
    case 13: return enumArray;
    case 14: return fixedArray;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }
  // Used by DatumReader.  Applications should not call. 
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: boolean$ = (java.lang.Boolean)value$; break;
    case 1: int$ = (java.lang.Integer)value$; break;
    case 2: long$ = (java.lang.Long)value$; break;
    case 3: float$ = (java.lang.Float)value$; break;
    case 4: double$ = (java.lang.Double)value$; break;
    case 5: string = (java.lang.CharSequence)value$; break;
    case 6: bytes = (java.nio.ByteBuffer)value$; break;
    case 7: nested = (com.databricks.spark.avro.SimpleRecord)value$; break;
    case 8: enum$ = (com.databricks.spark.avro.SimpleEnums)value$; break;
    case 9: fixed = (com.databricks.spark.avro.SimpleFixed)value$; break;
    case 10: intArray = (java.util.List<java.lang.Integer>)value$; break;
    case 11: stringArray = (java.util.List<java.lang.CharSequence>)value$; break;
    case 12: recordArray = (java.util.List<com.databricks.spark.avro.SimpleRecord>)value$; break;
    case 13: enumArray = (java.util.List<com.databricks.spark.avro.SimpleEnums>)value$; break;
    case 14: fixedArray = (java.util.List<com.databricks.spark.avro.SimpleFixed>)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  /**
   * Gets the value of the 'boolean$' field.
   */
  public java.lang.Boolean getBoolean$() {
    return boolean$;
  }

  /**
   * Sets the value of the 'boolean$' field.
   * @param value the value to set.
   */
  public void setBoolean$(java.lang.Boolean value) {
    this.boolean$ = value;
  }

  /**
   * Gets the value of the 'int$' field.
   */
  public java.lang.Integer getInt$() {
    return int$;
  }

  /**
   * Sets the value of the 'int$' field.
   * @param value the value to set.
   */
  public void setInt$(java.lang.Integer value) {
    this.int$ = value;
  }

  /**
   * Gets the value of the 'long$' field.
   */
  public java.lang.Long getLong$() {
    return long$;
  }

  /**
   * Sets the value of the 'long$' field.
   * @param value the value to set.
   */
  public void setLong$(java.lang.Long value) {
    this.long$ = value;
  }

  /**
   * Gets the value of the 'float$' field.
   */
  public java.lang.Float getFloat$() {
    return float$;
  }

  /**
   * Sets the value of the 'float$' field.
   * @param value the value to set.
   */
  public void setFloat$(java.lang.Float value) {
    this.float$ = value;
  }

  /**
   * Gets the value of the 'double$' field.
   */
  public java.lang.Double getDouble$() {
    return double$;
  }

  /**
   * Sets the value of the 'double$' field.
   * @param value the value to set.
   */
  public void setDouble$(java.lang.Double value) {
    this.double$ = value;
  }

  /**
   * Gets the value of the 'string' field.
   */
  public java.lang.CharSequence getString() {
    return string;
  }

  /**
   * Sets the value of the 'string' field.
   * @param value the value to set.
   */
  public void setString(java.lang.CharSequence value) {
    this.string = value;
  }

  /**
   * Gets the value of the 'bytes' field.
   */
  public java.nio.ByteBuffer getBytes() {
    return bytes;
  }

  /**
   * Sets the value of the 'bytes' field.
   * @param value the value to set.
   */
  public void setBytes(java.nio.ByteBuffer value) {
    this.bytes = value;
  }

  /**
   * Gets the value of the 'nested' field.
   */
  public com.databricks.spark.avro.SimpleRecord getNested() {
    return nested;
  }

  /**
   * Sets the value of the 'nested' field.
   * @param value the value to set.
   */
  public void setNested(com.databricks.spark.avro.SimpleRecord value) {
    this.nested = value;
  }

  /**
   * Gets the value of the 'enum$' field.
   */
  public com.databricks.spark.avro.SimpleEnums getEnum$() {
    return enum$;
  }

  /**
   * Sets the value of the 'enum$' field.
   * @param value the value to set.
   */
  public void setEnum$(com.databricks.spark.avro.SimpleEnums value) {
    this.enum$ = value;
  }

  /**
   * Gets the value of the 'fixed' field.
   */
  public com.databricks.spark.avro.SimpleFixed getFixed() {
    return fixed;
  }

  /**
   * Sets the value of the 'fixed' field.
   * @param value the value to set.
   */
  public void setFixed(com.databricks.spark.avro.SimpleFixed value) {
    this.fixed = value;
  }

  /**
   * Gets the value of the 'intArray' field.
   */
  public java.util.List<java.lang.Integer> getIntArray() {
    return intArray;
  }

  /**
   * Sets the value of the 'intArray' field.
   * @param value the value to set.
   */
  public void setIntArray(java.util.List<java.lang.Integer> value) {
    this.intArray = value;
  }

  /**
   * Gets the value of the 'stringArray' field.
   */
  public java.util.List<java.lang.CharSequence> getStringArray() {
    return stringArray;
  }

  /**
   * Sets the value of the 'stringArray' field.
   * @param value the value to set.
   */
  public void setStringArray(java.util.List<java.lang.CharSequence> value) {
    this.stringArray = value;
  }

  /**
   * Gets the value of the 'recordArray' field.
   */
  public java.util.List<com.databricks.spark.avro.SimpleRecord> getRecordArray() {
    return recordArray;
  }

  /**
   * Sets the value of the 'recordArray' field.
   * @param value the value to set.
   */
  public void setRecordArray(java.util.List<com.databricks.spark.avro.SimpleRecord> value) {
    this.recordArray = value;
  }

  /**
   * Gets the value of the 'enumArray' field.
   */
  public java.util.List<com.databricks.spark.avro.SimpleEnums> getEnumArray() {
    return enumArray;
  }

  /**
   * Sets the value of the 'enumArray' field.
   * @param value the value to set.
   */
  public void setEnumArray(java.util.List<com.databricks.spark.avro.SimpleEnums> value) {
    this.enumArray = value;
  }

  /**
   * Gets the value of the 'fixedArray' field.
   */
  public java.util.List<com.databricks.spark.avro.SimpleFixed> getFixedArray() {
    return fixedArray;
  }

  /**
   * Sets the value of the 'fixedArray' field.
   * @param value the value to set.
   */
  public void setFixedArray(java.util.List<com.databricks.spark.avro.SimpleFixed> value) {
    this.fixedArray = value;
  }

  /** Creates a new TestRecord RecordBuilder */
  public static com.databricks.spark.avro.TestRecord.Builder newBuilder() {
    return new com.databricks.spark.avro.TestRecord.Builder();
  }
  
  /** Creates a new TestRecord RecordBuilder by copying an existing Builder */
  public static com.databricks.spark.avro.TestRecord.Builder newBuilder(com.databricks.spark.avro.TestRecord.Builder other) {
    return new com.databricks.spark.avro.TestRecord.Builder(other);
  }
  
  /** Creates a new TestRecord RecordBuilder by copying an existing TestRecord instance */
  public static com.databricks.spark.avro.TestRecord.Builder newBuilder(com.databricks.spark.avro.TestRecord other) {
    return new com.databricks.spark.avro.TestRecord.Builder(other);
  }
  
  /**
   * RecordBuilder for TestRecord instances.
   */
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<TestRecord>
    implements org.apache.avro.data.RecordBuilder<TestRecord> {

    private boolean boolean$;
    private int int$;
    private long long$;
    private float float$;
    private double double$;
    private java.lang.CharSequence string;
    private java.nio.ByteBuffer bytes;
    private com.databricks.spark.avro.SimpleRecord nested;
    private com.databricks.spark.avro.SimpleEnums enum$;
    private com.databricks.spark.avro.SimpleFixed fixed;
    private java.util.List<java.lang.Integer> intArray;
    private java.util.List<java.lang.CharSequence> stringArray;
    private java.util.List<com.databricks.spark.avro.SimpleRecord> recordArray;
    private java.util.List<com.databricks.spark.avro.SimpleEnums> enumArray;
    private java.util.List<com.databricks.spark.avro.SimpleFixed> fixedArray;

    /** Creates a new Builder */
    private Builder() {
      super(com.databricks.spark.avro.TestRecord.SCHEMA$);
    }
    
    /** Creates a Builder by copying an existing Builder */
    private Builder(com.databricks.spark.avro.TestRecord.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.boolean$)) {
        this.boolean$ = data().deepCopy(fields()[0].schema(), other.boolean$);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.int$)) {
        this.int$ = data().deepCopy(fields()[1].schema(), other.int$);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.long$)) {
        this.long$ = data().deepCopy(fields()[2].schema(), other.long$);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.float$)) {
        this.float$ = data().deepCopy(fields()[3].schema(), other.float$);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.double$)) {
        this.double$ = data().deepCopy(fields()[4].schema(), other.double$);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.string)) {
        this.string = data().deepCopy(fields()[5].schema(), other.string);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.bytes)) {
        this.bytes = data().deepCopy(fields()[6].schema(), other.bytes);
        fieldSetFlags()[6] = true;
      }
      if (isValidValue(fields()[7], other.nested)) {
        this.nested = data().deepCopy(fields()[7].schema(), other.nested);
        fieldSetFlags()[7] = true;
      }
      if (isValidValue(fields()[8], other.enum$)) {
        this.enum$ = data().deepCopy(fields()[8].schema(), other.enum$);
        fieldSetFlags()[8] = true;
      }
      if (isValidValue(fields()[9], other.fixed)) {
        this.fixed = data().deepCopy(fields()[9].schema(), other.fixed);
        fieldSetFlags()[9] = true;
      }
      if (isValidValue(fields()[10], other.intArray)) {
        this.intArray = data().deepCopy(fields()[10].schema(), other.intArray);
        fieldSetFlags()[10] = true;
      }
      if (isValidValue(fields()[11], other.stringArray)) {
        this.stringArray = data().deepCopy(fields()[11].schema(), other.stringArray);
        fieldSetFlags()[11] = true;
      }
      if (isValidValue(fields()[12], other.recordArray)) {
        this.recordArray = data().deepCopy(fields()[12].schema(), other.recordArray);
        fieldSetFlags()[12] = true;
      }
      if (isValidValue(fields()[13], other.enumArray)) {
        this.enumArray = data().deepCopy(fields()[13].schema(), other.enumArray);
        fieldSetFlags()[13] = true;
      }
      if (isValidValue(fields()[14], other.fixedArray)) {
        this.fixedArray = data().deepCopy(fields()[14].schema(), other.fixedArray);
        fieldSetFlags()[14] = true;
      }
    }
    
    /** Creates a Builder by copying an existing TestRecord instance */
    private Builder(com.databricks.spark.avro.TestRecord other) {
            super(com.databricks.spark.avro.TestRecord.SCHEMA$);
      if (isValidValue(fields()[0], other.boolean$)) {
        this.boolean$ = data().deepCopy(fields()[0].schema(), other.boolean$);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.int$)) {
        this.int$ = data().deepCopy(fields()[1].schema(), other.int$);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.long$)) {
        this.long$ = data().deepCopy(fields()[2].schema(), other.long$);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.float$)) {
        this.float$ = data().deepCopy(fields()[3].schema(), other.float$);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.double$)) {
        this.double$ = data().deepCopy(fields()[4].schema(), other.double$);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.string)) {
        this.string = data().deepCopy(fields()[5].schema(), other.string);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.bytes)) {
        this.bytes = data().deepCopy(fields()[6].schema(), other.bytes);
        fieldSetFlags()[6] = true;
      }
      if (isValidValue(fields()[7], other.nested)) {
        this.nested = data().deepCopy(fields()[7].schema(), other.nested);
        fieldSetFlags()[7] = true;
      }
      if (isValidValue(fields()[8], other.enum$)) {
        this.enum$ = data().deepCopy(fields()[8].schema(), other.enum$);
        fieldSetFlags()[8] = true;
      }
      if (isValidValue(fields()[9], other.fixed)) {
        this.fixed = data().deepCopy(fields()[9].schema(), other.fixed);
        fieldSetFlags()[9] = true;
      }
      if (isValidValue(fields()[10], other.intArray)) {
        this.intArray = data().deepCopy(fields()[10].schema(), other.intArray);
        fieldSetFlags()[10] = true;
      }
      if (isValidValue(fields()[11], other.stringArray)) {
        this.stringArray = data().deepCopy(fields()[11].schema(), other.stringArray);
        fieldSetFlags()[11] = true;
      }
      if (isValidValue(fields()[12], other.recordArray)) {
        this.recordArray = data().deepCopy(fields()[12].schema(), other.recordArray);
        fieldSetFlags()[12] = true;
      }
      if (isValidValue(fields()[13], other.enumArray)) {
        this.enumArray = data().deepCopy(fields()[13].schema(), other.enumArray);
        fieldSetFlags()[13] = true;
      }
      if (isValidValue(fields()[14], other.fixedArray)) {
        this.fixedArray = data().deepCopy(fields()[14].schema(), other.fixedArray);
        fieldSetFlags()[14] = true;
      }
    }

    /** Gets the value of the 'boolean$' field */
    public java.lang.Boolean getBoolean$() {
      return boolean$;
    }
    
    /** Sets the value of the 'boolean$' field */
    public com.databricks.spark.avro.TestRecord.Builder setBoolean$(boolean value) {
      validate(fields()[0], value);
      this.boolean$ = value;
      fieldSetFlags()[0] = true;
      return this; 
    }
    
    /** Checks whether the 'boolean$' field has been set */
    public boolean hasBoolean$() {
      return fieldSetFlags()[0];
    }
    
    /** Clears the value of the 'boolean$' field */
    public com.databricks.spark.avro.TestRecord.Builder clearBoolean$() {
      fieldSetFlags()[0] = false;
      return this;
    }

    /** Gets the value of the 'int$' field */
    public java.lang.Integer getInt$() {
      return int$;
    }
    
    /** Sets the value of the 'int$' field */
    public com.databricks.spark.avro.TestRecord.Builder setInt$(int value) {
      validate(fields()[1], value);
      this.int$ = value;
      fieldSetFlags()[1] = true;
      return this; 
    }
    
    /** Checks whether the 'int$' field has been set */
    public boolean hasInt$() {
      return fieldSetFlags()[1];
    }
    
    /** Clears the value of the 'int$' field */
    public com.databricks.spark.avro.TestRecord.Builder clearInt$() {
      fieldSetFlags()[1] = false;
      return this;
    }

    /** Gets the value of the 'long$' field */
    public java.lang.Long getLong$() {
      return long$;
    }
    
    /** Sets the value of the 'long$' field */
    public com.databricks.spark.avro.TestRecord.Builder setLong$(long value) {
      validate(fields()[2], value);
      this.long$ = value;
      fieldSetFlags()[2] = true;
      return this; 
    }
    
    /** Checks whether the 'long$' field has been set */
    public boolean hasLong$() {
      return fieldSetFlags()[2];
    }
    
    /** Clears the value of the 'long$' field */
    public com.databricks.spark.avro.TestRecord.Builder clearLong$() {
      fieldSetFlags()[2] = false;
      return this;
    }

    /** Gets the value of the 'float$' field */
    public java.lang.Float getFloat$() {
      return float$;
    }
    
    /** Sets the value of the 'float$' field */
    public com.databricks.spark.avro.TestRecord.Builder setFloat$(float value) {
      validate(fields()[3], value);
      this.float$ = value;
      fieldSetFlags()[3] = true;
      return this; 
    }
    
    /** Checks whether the 'float$' field has been set */
    public boolean hasFloat$() {
      return fieldSetFlags()[3];
    }
    
    /** Clears the value of the 'float$' field */
    public com.databricks.spark.avro.TestRecord.Builder clearFloat$() {
      fieldSetFlags()[3] = false;
      return this;
    }

    /** Gets the value of the 'double$' field */
    public java.lang.Double getDouble$() {
      return double$;
    }
    
    /** Sets the value of the 'double$' field */
    public com.databricks.spark.avro.TestRecord.Builder setDouble$(double value) {
      validate(fields()[4], value);
      this.double$ = value;
      fieldSetFlags()[4] = true;
      return this; 
    }
    
    /** Checks whether the 'double$' field has been set */
    public boolean hasDouble$() {
      return fieldSetFlags()[4];
    }
    
    /** Clears the value of the 'double$' field */
    public com.databricks.spark.avro.TestRecord.Builder clearDouble$() {
      fieldSetFlags()[4] = false;
      return this;
    }

    /** Gets the value of the 'string' field */
    public java.lang.CharSequence getString() {
      return string;
    }
    
    /** Sets the value of the 'string' field */
    public com.databricks.spark.avro.TestRecord.Builder setString(java.lang.CharSequence value) {
      validate(fields()[5], value);
      this.string = value;
      fieldSetFlags()[5] = true;
      return this; 
    }
    
    /** Checks whether the 'string' field has been set */
    public boolean hasString() {
      return fieldSetFlags()[5];
    }
    
    /** Clears the value of the 'string' field */
    public com.databricks.spark.avro.TestRecord.Builder clearString() {
      string = null;
      fieldSetFlags()[5] = false;
      return this;
    }

    /** Gets the value of the 'bytes' field */
    public java.nio.ByteBuffer getBytes() {
      return bytes;
    }
    
    /** Sets the value of the 'bytes' field */
    public com.databricks.spark.avro.TestRecord.Builder setBytes(java.nio.ByteBuffer value) {
      validate(fields()[6], value);
      this.bytes = value;
      fieldSetFlags()[6] = true;
      return this; 
    }
    
    /** Checks whether the 'bytes' field has been set */
    public boolean hasBytes() {
      return fieldSetFlags()[6];
    }
    
    /** Clears the value of the 'bytes' field */
    public com.databricks.spark.avro.TestRecord.Builder clearBytes() {
      bytes = null;
      fieldSetFlags()[6] = false;
      return this;
    }

    /** Gets the value of the 'nested' field */
    public com.databricks.spark.avro.SimpleRecord getNested() {
      return nested;
    }
    
    /** Sets the value of the 'nested' field */
    public com.databricks.spark.avro.TestRecord.Builder setNested(com.databricks.spark.avro.SimpleRecord value) {
      validate(fields()[7], value);
      this.nested = value;
      fieldSetFlags()[7] = true;
      return this; 
    }
    
    /** Checks whether the 'nested' field has been set */
    public boolean hasNested() {
      return fieldSetFlags()[7];
    }
    
    /** Clears the value of the 'nested' field */
    public com.databricks.spark.avro.TestRecord.Builder clearNested() {
      nested = null;
      fieldSetFlags()[7] = false;
      return this;
    }

    /** Gets the value of the 'enum$' field */
    public com.databricks.spark.avro.SimpleEnums getEnum$() {
      return enum$;
    }
    
    /** Sets the value of the 'enum$' field */
    public com.databricks.spark.avro.TestRecord.Builder setEnum$(com.databricks.spark.avro.SimpleEnums value) {
      validate(fields()[8], value);
      this.enum$ = value;
      fieldSetFlags()[8] = true;
      return this; 
    }
    
    /** Checks whether the 'enum$' field has been set */
    public boolean hasEnum$() {
      return fieldSetFlags()[8];
    }
    
    /** Clears the value of the 'enum$' field */
    public com.databricks.spark.avro.TestRecord.Builder clearEnum$() {
      enum$ = null;
      fieldSetFlags()[8] = false;
      return this;
    }

    /** Gets the value of the 'fixed' field */
    public com.databricks.spark.avro.SimpleFixed getFixed() {
      return fixed;
    }
    
    /** Sets the value of the 'fixed' field */
    public com.databricks.spark.avro.TestRecord.Builder setFixed(com.databricks.spark.avro.SimpleFixed value) {
      validate(fields()[9], value);
      this.fixed = value;
      fieldSetFlags()[9] = true;
      return this; 
    }
    
    /** Checks whether the 'fixed' field has been set */
    public boolean hasFixed() {
      return fieldSetFlags()[9];
    }
    
    /** Clears the value of the 'fixed' field */
    public com.databricks.spark.avro.TestRecord.Builder clearFixed() {
      fixed = null;
      fieldSetFlags()[9] = false;
      return this;
    }

    /** Gets the value of the 'intArray' field */
    public java.util.List<java.lang.Integer> getIntArray() {
      return intArray;
    }
    
    /** Sets the value of the 'intArray' field */
    public com.databricks.spark.avro.TestRecord.Builder setIntArray(java.util.List<java.lang.Integer> value) {
      validate(fields()[10], value);
      this.intArray = value;
      fieldSetFlags()[10] = true;
      return this; 
    }
    
    /** Checks whether the 'intArray' field has been set */
    public boolean hasIntArray() {
      return fieldSetFlags()[10];
    }
    
    /** Clears the value of the 'intArray' field */
    public com.databricks.spark.avro.TestRecord.Builder clearIntArray() {
      intArray = null;
      fieldSetFlags()[10] = false;
      return this;
    }

    /** Gets the value of the 'stringArray' field */
    public java.util.List<java.lang.CharSequence> getStringArray() {
      return stringArray;
    }
    
    /** Sets the value of the 'stringArray' field */
    public com.databricks.spark.avro.TestRecord.Builder setStringArray(java.util.List<java.lang.CharSequence> value) {
      validate(fields()[11], value);
      this.stringArray = value;
      fieldSetFlags()[11] = true;
      return this; 
    }
    
    /** Checks whether the 'stringArray' field has been set */
    public boolean hasStringArray() {
      return fieldSetFlags()[11];
    }
    
    /** Clears the value of the 'stringArray' field */
    public com.databricks.spark.avro.TestRecord.Builder clearStringArray() {
      stringArray = null;
      fieldSetFlags()[11] = false;
      return this;
    }

    /** Gets the value of the 'recordArray' field */
    public java.util.List<com.databricks.spark.avro.SimpleRecord> getRecordArray() {
      return recordArray;
    }
    
    /** Sets the value of the 'recordArray' field */
    public com.databricks.spark.avro.TestRecord.Builder setRecordArray(java.util.List<com.databricks.spark.avro.SimpleRecord> value) {
      validate(fields()[12], value);
      this.recordArray = value;
      fieldSetFlags()[12] = true;
      return this; 
    }
    
    /** Checks whether the 'recordArray' field has been set */
    public boolean hasRecordArray() {
      return fieldSetFlags()[12];
    }
    
    /** Clears the value of the 'recordArray' field */
    public com.databricks.spark.avro.TestRecord.Builder clearRecordArray() {
      recordArray = null;
      fieldSetFlags()[12] = false;
      return this;
    }

    /** Gets the value of the 'enumArray' field */
    public java.util.List<com.databricks.spark.avro.SimpleEnums> getEnumArray() {
      return enumArray;
    }
    
    /** Sets the value of the 'enumArray' field */
    public com.databricks.spark.avro.TestRecord.Builder setEnumArray(java.util.List<com.databricks.spark.avro.SimpleEnums> value) {
      validate(fields()[13], value);
      this.enumArray = value;
      fieldSetFlags()[13] = true;
      return this; 
    }
    
    /** Checks whether the 'enumArray' field has been set */
    public boolean hasEnumArray() {
      return fieldSetFlags()[13];
    }
    
    /** Clears the value of the 'enumArray' field */
    public com.databricks.spark.avro.TestRecord.Builder clearEnumArray() {
      enumArray = null;
      fieldSetFlags()[13] = false;
      return this;
    }

    /** Gets the value of the 'fixedArray' field */
    public java.util.List<com.databricks.spark.avro.SimpleFixed> getFixedArray() {
      return fixedArray;
    }
    
    /** Sets the value of the 'fixedArray' field */
    public com.databricks.spark.avro.TestRecord.Builder setFixedArray(java.util.List<com.databricks.spark.avro.SimpleFixed> value) {
      validate(fields()[14], value);
      this.fixedArray = value;
      fieldSetFlags()[14] = true;
      return this; 
    }
    
    /** Checks whether the 'fixedArray' field has been set */
    public boolean hasFixedArray() {
      return fieldSetFlags()[14];
    }
    
    /** Clears the value of the 'fixedArray' field */
    public com.databricks.spark.avro.TestRecord.Builder clearFixedArray() {
      fixedArray = null;
      fieldSetFlags()[14] = false;
      return this;
    }

    @Override
    public TestRecord build() {
      try {
        TestRecord record = new TestRecord();
        record.boolean$ = fieldSetFlags()[0] ? this.boolean$ : (java.lang.Boolean) defaultValue(fields()[0]);
        record.int$ = fieldSetFlags()[1] ? this.int$ : (java.lang.Integer) defaultValue(fields()[1]);
        record.long$ = fieldSetFlags()[2] ? this.long$ : (java.lang.Long) defaultValue(fields()[2]);
        record.float$ = fieldSetFlags()[3] ? this.float$ : (java.lang.Float) defaultValue(fields()[3]);
        record.double$ = fieldSetFlags()[4] ? this.double$ : (java.lang.Double) defaultValue(fields()[4]);
        record.string = fieldSetFlags()[5] ? this.string : (java.lang.CharSequence) defaultValue(fields()[5]);
        record.bytes = fieldSetFlags()[6] ? this.bytes : (java.nio.ByteBuffer) defaultValue(fields()[6]);
        record.nested = fieldSetFlags()[7] ? this.nested : (com.databricks.spark.avro.SimpleRecord) defaultValue(fields()[7]);
        record.enum$ = fieldSetFlags()[8] ? this.enum$ : (com.databricks.spark.avro.SimpleEnums) defaultValue(fields()[8]);
        record.fixed = fieldSetFlags()[9] ? this.fixed : (com.databricks.spark.avro.SimpleFixed) defaultValue(fields()[9]);
        record.intArray = fieldSetFlags()[10] ? this.intArray : (java.util.List<java.lang.Integer>) defaultValue(fields()[10]);
        record.stringArray = fieldSetFlags()[11] ? this.stringArray : (java.util.List<java.lang.CharSequence>) defaultValue(fields()[11]);
        record.recordArray = fieldSetFlags()[12] ? this.recordArray : (java.util.List<com.databricks.spark.avro.SimpleRecord>) defaultValue(fields()[12]);
        record.enumArray = fieldSetFlags()[13] ? this.enumArray : (java.util.List<com.databricks.spark.avro.SimpleEnums>) defaultValue(fields()[13]);
        record.fixedArray = fieldSetFlags()[14] ? this.fixedArray : (java.util.List<com.databricks.spark.avro.SimpleFixed>) defaultValue(fields()[14]);
        return record;
      } catch (Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }
}
